1. Artificial Intelligence (AI)

Definition: The broadest concept. AI is the science of making machines â€œthinkâ€ or â€œactâ€ intelligently like humans.

Goal: Enable machines to mimic human intelligence â€” reasoning, problem-solving, decision-making, learning.

Examples:

Virtual assistants (Siri, Alexa)

Chess-playing computers

Chatbots

Fraud detection systems

2. Machine Learning (ML)

Definition: A subset of AI that focuses on systems that learn automatically from data without being explicitly programmed.

Goal: Use algorithms to detect patterns, make predictions, or improve performance with experience (data).

Examples:

Email spam filters

Predicting house prices
Features (Inputs) â†’ Area, Bedrooms, Location Score, Age of House

Label (Output) â†’ House Price

Here, the ML model learns complex relationships:

Larger area â†’ Higher price

More bedrooms â†’ Higher price

Better location â†’ Higher price

Older house â†’ Lower price

Recommendation systems (Netflix, Amazon)

3. Deep Learning (DL)

Definition: A subset of ML that uses artificial neural networks with many layers (deep neural networks).

Goal: Handle large, complex data (images, videos, text, speech) and automatically extract features without manual intervention.

Examples:
For an image of a cat ğŸ±:

Layer 1 â†’ detects edges (lines, corners)

Layer 2 â†’ detects shapes (ears, eyes)

Layer 3 â†’ detects object parts (face, legs)

Final Layer â†’ predicts â€œCatâ€
Image recognition (face unlock in phones)

Speech recognition (Google Translate voice)

Self-driving cars

ChatGPT

Train-Test Split
What is Train-Test Split?

When we build a machine learning model, we donâ€™t give it all the data at once.
We split the dataset into two (sometimes three) parts:

Training Set â†’

Used to teach the model.

The model looks at input features and corresponding labels (answers) to learn patterns.

Test Set â†’

Used to evaluate how well the model performs on unseen data.

This tells us if the model has really learned, or if it just memorized the training data (overfitting).

SkLearn(Scikit-learn)
What is scikit-learn (sklearn)?

scikit-learn is a Python library for Machine Learning.

It provides simple, efficient tools for data analysis, preprocessing, training ML models, and evaluation.

Built on top of NumPy, SciPy, and Matplotlib â†’ which makes it fast and reliable.
Why do we use sklearn?

Because it makes ML workflows super easy:

Preprocessing data â†’ handling missing values, scaling, encoding categories.

Splitting data â†’ train_test_split for train & test sets.

Training models â†’ logistic regression, decision trees, random forest, SVM, KNN, etc.

Evaluating models â†’ accuracy, confusion matrix, precision, recall, F1-score.

Saving/loading models â†’ so you donâ€™t need to retrain every time.

1. Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split

pandas â†’ to create and handle tabular dataset.

train_test_split â†’ function that splits data into training and testing sets.

data = pd.DataFrame({
    "Hours_Studied": [2, 4, 6, 8, 10, 1, 9, 5],
    "Attendance": [60, 65, 70, 80, 85, 50, 90, 60],
    "Result": [0, 0, 1, 1, 1, 0, 1, 0]  # 0 = Fail, 1 = Pass
})

3. Separate Features and Target
X = data[["Hours_Studied", "Attendance"]]
y = data["Result"]

X (features): Independent variables â†’ inputs to the model.
(Hours_Studied, Attendance)

y (target/label): Dependent variable â†’ output to be predicted.
(Result)

4. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=1
)
test_size=0.25 â†’ 25% data goes to test set, 75% to training set.

random_state=1 â†’ fixes the randomness so results are reproducible.

print("Training Data:")
print(X_train)
print("\nTesting Data:")
print(X_test)

Data preprocessing recap

1. Data Collection

Gather data from different sources (CSV, Excel, SQL, APIs, web scraping, etc.).

Ensure consistency across datasets.

2. Data Cleaning

Handling missing values:

Remove rows/columns with too many missing values.

Fill with mean/median/mode or forward/backward fill.

Remove duplicates.

Handle outliers using IQR, z-score, or domain knowledge.

3. Data Transformation

Encoding categorical variables:

Label Encoding (for ordinal data).

One-Hot Encoding (for nominal data).

Feature scaling:

Standardization (mean = 0, std = 1).

Normalization (range 0â€“1).

Log/Power transformation for skewed distributions.

Steps in EDA for Predictive Modeling
1. Understand the Target Variable

Is it classification (Yes/No, categories) or regression (numeric)?

Plot distribution of the target:

Histogram for numeric targets.

Bar plot for categorical targets.

Check imbalance (e.g., 90% No, 10% Y

2. Check Data Quality

Missing values (imputation strategies).

Duplicates, inconsistent categories.

Outliers (might affect regression/classification).

3. Univariate Analysis (Features Alone)

Numerical features â†’ histograms, boxplots.

Categorical features â†’ countplots, pie charts.
ğŸ‘‰ Helps see skewness, transformations needed, etc.

4. Bivariate Analysis (Features vs Target)

Numeric vs Target:

Correlation heatmap (Pearson/Spearman).

Boxplot of numeric feature grouped by target.

Categorical vs Target:

Grouped bar plots.

Chi-square test of independence.

5. Multivariate Analysis

Feature interactions (pairplots, scatter plots).

Data Splitting Consideration

Always do EDA only on training set (to avoid data leakage).

